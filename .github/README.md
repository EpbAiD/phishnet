# GitHub Actions Workflows

Automated CI/CD pipeline for PhishNet phishing detection system.

## ğŸ“‹ Workflows Overview

| Workflow | Trigger | Duration | Purpose |
|----------|---------|----------|---------|
| [Daily Data Pipeline](workflows/daily_data_pipeline.yml) | Daily 2 AM UTC | ~30 min | Collect URLs, upload to VM |
| [VM Processing Monitor](workflows/vm_processing_monitor.yml) | Auto-triggered | 2-8 hours | Monitor VM, validate data, retrain models |
| [Model Performance Monitor](workflows/model_performance_monitor.yml) | After retraining | ~10 min | Evaluate models, detect drift |
| [Web Deployment](workflows/deploy_web.yml) | Push to main | ~5 min | Deploy website & extension |
| [CI/CD Pipeline](workflows/ci.yml) | Push/PR | ~15 min | Tests, linting, Docker build |

## ğŸš€ Quick Start

**New to GitHub Actions?** See [QUICK_START.md](QUICK_START.md)

**Full setup guide:** See [WORKFLOWS_SETUP.md](WORKFLOWS_SETUP.md)

## ğŸ”‘ Required Secrets

| Secret Name | Description | Required For |
|-------------|-------------|--------------|
| `GCP_SA_KEY` | Google Cloud service account key (JSON) | All VM workflows |

## ğŸ“Š Workflow Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Daily Data Pipeline                       â”‚
â”‚  â€¢ Fetch URLs from sources                                   â”‚
â”‚  â€¢ Extract URL features                                      â”‚
â”‚  â€¢ Start GCP VM                                              â”‚
â”‚  â€¢ Upload to VM queue                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ triggers
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               VM Processing Monitor                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Monitor Loop (every 5 min, max 8 hours)     â”‚           â”‚
â”‚  â”‚  â€¢ Check DNS/WHOIS CSV row counts            â”‚           â”‚
â”‚  â”‚  â€¢ Wait for completion (1001 rows each)      â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Data Quality Validation                     â”‚           â”‚
â”‚  â”‚  â€¢ Download CSV files from VM                â”‚           â”‚
â”‚  â”‚  â€¢ Check row counts match                    â”‚           â”‚
â”‚  â”‚  â€¢ Validate success rates (95%+)             â”‚           â”‚
â”‚  â”‚  â€¢ Upload as artifacts                       â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Model Retraining                            â”‚           â”‚
â”‚  â”‚  â€¢ Merge VM data with main dataset           â”‚           â”‚
â”‚  â”‚  â€¢ Train URL/DNS/WHOIS/Ensemble models       â”‚           â”‚
â”‚  â”‚  â€¢ Save models to repository                 â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  VM Auto-Stop (cost optimization)            â”‚           â”‚
â”‚  â”‚  â€¢ Stop VM after processing                  â”‚           â”‚
â”‚  â”‚  â€¢ Save ~$2-3/day                            â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ triggers
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Model Performance Monitoring                      â”‚
â”‚  â€¢ Evaluate on test set                                      â”‚
â”‚  â€¢ Calculate metrics (acc, prec, recall, F1, AUC)            â”‚
â”‚  â€¢ Compare with historical performance                       â”‚
â”‚  â€¢ Detect drift (>5% degradation)                            â”‚
â”‚  â€¢ Save performance history                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Web Deployment                               â”‚
â”‚  â€¢ Build web interface                                       â”‚
â”‚  â€¢ Build browser extension                                   â”‚
â”‚  â€¢ Deploy to GitHub Pages                                    â”‚
â”‚  â€¢ Available at: username.github.io/repo                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## â±ï¸ Execution Schedule

```
Daily Schedule (UTC):
02:00 - Daily Data Pipeline starts
02:30 - VM processing begins
10:30 - VM processing completes (estimated)
10:45 - Model retraining completes
11:00 - Performance monitoring completes
11:05 - Web deployment (if models updated)
```

## ğŸ“¦ Artifacts

Workflows generate downloadable artifacts:

| Artifact | Retention | Size | Description |
|----------|-----------|------|-------------|
| `validated-features-YYYYMMDD` | 30 days | ~5-10 MB | DNS/WHOIS CSV files |
| `trained-models-YYYYMMDD` | 90 days | ~50-100 MB | Trained model files |
| `model-performance-report` | 30 days | <1 MB | JSON with metrics |

## ğŸ¯ Success Criteria

| Check | Threshold | Action if Failed |
|-------|-----------|------------------|
| DNS success rate | â‰¥95% | Workflow fails, investigate |
| WHOIS success rate | â‰¥95% | Workflow fails, investigate |
| Model accuracy | â‰¥90% | Warning, but continues |
| Model drift | <5% degradation | Warning, flag for review |

## ğŸ’° Cost Estimation

### GitHub Actions
- **Free tier**: 2,000 minutes/month
- **Expected usage**: ~900 minutes/month
- **Cost**: $0 (within free tier)

### GCP VM
- **Running**: $0.10-0.30/hour (depends on instance type)
- **Daily processing**: ~8 hours
- **Daily cost**: $0.80-2.40
- **Monthly cost**: $25-75

### Total: ~$25-75/month

**Optimization**: VM auto-stop saves ~$2-3/day compared to always-on.

## ğŸ”§ Customization

### Change Schedule

Edit [daily_data_pipeline.yml](workflows/daily_data_pipeline.yml):

```yaml
schedule:
  - cron: '0 14 * * *'  # 2 PM UTC instead of 2 AM
```

### Change VM Configuration

Edit workflow env vars:

```yaml
env:
  VM_NAME: your-vm-name
  GCP_ZONE: your-zone
```

### Disable Auto-VM-Stop

Comment out `stop-vm` job in [vm_processing_monitor.yml](workflows/vm_processing_monitor.yml)

## ğŸ› Troubleshooting

### Workflow not triggering on schedule?
- Repository must be active (GitHub disables inactive repos)
- Workflow must be on default branch (main)
- Check Actions are enabled in repository settings

### GCP authentication failing?
- Verify `GCP_SA_KEY` secret is set correctly
- Check service account has `compute.instanceAdmin.v1` role
- Ensure JSON is valid (not corrupted)

### VM processing timeout?
- Increase `max_wait_hours` input
- Increase VM resources (CPU/memory)
- Consider self-hosted runner for longer runs

### Data quality validation failing?
- Check VM processing logs
- Verify feature extraction scripts working
- Review success rate thresholds

## ğŸ“š Documentation

- [Quick Start Guide](QUICK_START.md) - 5-minute setup
- [Full Setup Guide](WORKFLOWS_SETUP.md) - Detailed documentation
- [GitHub Actions Docs](https://docs.github.com/actions) - Official documentation

## ğŸ”’ Security

- All secrets stored in GitHub Secrets (encrypted)
- GCP service account uses principle of least privilege
- No secrets in logs or artifacts
- Repository-scoped tokens (can't access other repos)

## ğŸ“ˆ Monitoring

**View workflow runs**: `https://github.com/YOUR_USERNAME/YOUR_REPO/actions`

**View website**: `https://YOUR_USERNAME.github.io/YOUR_REPO/`

**Check VM status**:
```bash
gcloud compute instances describe dns-whois-fetch-25 --zone=us-central1-c
```

---

## Author

**Eeshan Bhanap**
Columbia University
eb3658@columbia.edu

## License

See repository LICENSE file.
