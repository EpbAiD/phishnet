name: 10-Run Validation (Progressive Learning)

# Run 10 iterations of the E2E pipeline:
# Each run collects 100 NEW unique URLs (checking against master dataset)
# Features are extracted and appended to master
# 45 models are trained on the growing dataset
# Best ensemble is evaluated
# Final test shows progressive improvement

on:
  workflow_dispatch:
    inputs:
      run_count:
        description: 'Number of validation runs (1-10)'
        required: false
        default: '10'
      urls_per_run:
        description: 'New URLs to collect per run'
        required: false
        default: '100'

env:
  AWS_REGION: us-east-1
  S3_BUCKET: phishnet-data
  EC2_INSTANCE_ID: i-0c8ab11c281702a22

jobs:
  # ========================================================================
  # Single job that runs all 10 iterations sequentially
  # ========================================================================
  validation:
    name: "Run 10 Validation Iterations"
    runs-on: ubuntu-latest
    timeout-minutes: 600  # 10 hours max

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: pip install -r requirements.txt boto3 pyarrow

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup SSH key for EC2
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_SSH_KEY }}" > ~/.ssh/ec2_key
          chmod 600 ~/.ssh/ec2_key
          # Verify key was written
          echo "SSH key file size: $(wc -c < ~/.ssh/ec2_key) bytes"
          head -1 ~/.ssh/ec2_key

      - name: Run validation loop
        run: |
          TOTAL_RUNS="${{ github.event.inputs.run_count || '10' }}"
          URLS_PER_RUN="${{ github.event.inputs.urls_per_run || '100' }}"

          echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
          echo "‚ïë         10-RUN PROGRESSIVE LEARNING VALIDATION               ‚ïë"
          echo "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£"
          echo "‚ïë  Runs: $TOTAL_RUNS | URLs per run: $URLS_PER_RUN                          ‚ïë"
          echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
          echo ""

          # Create results tracking file
          mkdir -p analysis/validation_runs
          RESULTS_FILE="analysis/validation_runs/results_$(date +%Y%m%d_%H%M%S).csv"
          echo "run,total_urls,new_urls_added,phishing,legitimate,best_accuracy,best_f1,best_ensemble" > $RESULTS_FILE

          for RUN_NUM in $(seq 1 $TOTAL_RUNS); do
            echo ""
            echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
            echo "                    RUN $RUN_NUM of $TOTAL_RUNS"
            echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
            echo ""

            BATCH_DATE=$(date +%Y%m%d_%H%M%S)
            BATCH_FILE="data/url_queue/batch_${BATCH_DATE}.csv"
            mkdir -p data/url_queue data/processed

            # ------------------------------------------------------------
            # STEP 1: Download master for duplicate checking
            # ------------------------------------------------------------
            echo "üì• Step 1: Downloading master dataset..."
            aws s3 cp s3://${{ env.S3_BUCKET }}/master/phishing_features_master.csv data/processed/phishing_features_complete.csv 2>/dev/null || {
              echo "   Creating new master dataset"
              echo "url,label" > data/processed/phishing_features_complete.csv
            }

            BEFORE_COUNT=$(tail -n +2 data/processed/phishing_features_complete.csv 2>/dev/null | wc -l | tr -d ' ' || echo "0")
            echo "   Master contains $BEFORE_COUNT existing URLs"

            # ------------------------------------------------------------
            # STEP 2: Collect NEW unique URLs
            # ------------------------------------------------------------
            echo ""
            echo "üîó Step 2: Collecting $URLS_PER_RUN NEW unique URLs..."
            python3 scripts/fetch_urls.py $BATCH_FILE $URLS_PER_RUN || {
              echo "‚ö†Ô∏è URL collection failed, trying with smaller batch"
              python3 scripts/fetch_urls.py $BATCH_FILE 50 || true
            }

            if [ ! -f "$BATCH_FILE" ]; then
              echo "‚ùå Failed to collect URLs, skipping this run"
              continue
            fi

            # Count results
            TOTAL=$(tail -n +2 $BATCH_FILE 2>/dev/null | wc -l | tr -d ' ' || echo "0")
            PHISHING=$(grep -c ",phishing" $BATCH_FILE 2>/dev/null || echo "0")
            LEGIT=$(grep -c ",legitimate" $BATCH_FILE 2>/dev/null || echo "0")

            echo "   Collected: $TOTAL URLs (Phishing: $PHISHING, Legitimate: $LEGIT)"

            if [ "$TOTAL" -lt 5 ]; then
              echo "‚ö†Ô∏è Too few URLs collected ($TOTAL), skipping this run"
              continue
            fi

            # ------------------------------------------------------------
            # STEP 3: Extract URL features locally
            # ------------------------------------------------------------
            echo ""
            echo "üîç Step 3: Extracting URL features locally..."
            URL_FEATURES="data/processed/url_features_${BATCH_DATE}.csv"
            python3 scripts/extract_url_features.py $BATCH_FILE $URL_FEATURES

            # ------------------------------------------------------------
            # STEP 4: Upload to S3 and process on EC2
            # ------------------------------------------------------------
            echo ""
            echo "üì§ Step 4: Uploading to S3..."
            aws s3 cp $BATCH_FILE s3://${{ env.S3_BUCKET }}/queue/batch_${BATCH_DATE}.csv
            aws s3 cp $URL_FEATURES s3://${{ env.S3_BUCKET }}/queue/url_features_${BATCH_DATE}.csv
            aws s3 cp scripts/extract_vm_features_aws.py s3://${{ env.S3_BUCKET }}/scripts/

            echo ""
            echo "üñ•Ô∏è Step 5: Starting EC2 for DNS/WHOIS extraction..."

            # Check current state and handle accordingly
            INSTANCE_STATE=$(aws ec2 describe-instances --instance-ids ${{ env.EC2_INSTANCE_ID }} --query 'Reservations[0].Instances[0].State.Name' --output text)
            echo "   Current state: $INSTANCE_STATE"

            if [ "$INSTANCE_STATE" = "stopped" ]; then
              echo "   Starting instance..."
              aws ec2 start-instances --instance-ids ${{ env.EC2_INSTANCE_ID }}
              aws ec2 wait instance-running --instance-ids ${{ env.EC2_INSTANCE_ID }}
              sleep 60  # Wait for SSH to be ready
            elif [ "$INSTANCE_STATE" = "stopping" ]; then
              echo "   Waiting for instance to stop..."
              aws ec2 wait instance-stopped --instance-ids ${{ env.EC2_INSTANCE_ID }}
              echo "   Starting instance..."
              aws ec2 start-instances --instance-ids ${{ env.EC2_INSTANCE_ID }}
              aws ec2 wait instance-running --instance-ids ${{ env.EC2_INSTANCE_ID }}
              sleep 60  # Wait for SSH to be ready
            elif [ "$INSTANCE_STATE" = "pending" ]; then
              echo "   Waiting for instance to start..."
              aws ec2 wait instance-running --instance-ids ${{ env.EC2_INSTANCE_ID }}
              sleep 60  # Wait for SSH to be ready
            elif [ "$INSTANCE_STATE" = "running" ]; then
              echo "   Instance already running"
              sleep 10  # Brief wait for any ongoing operations
            else
              echo "   Unknown state: $INSTANCE_STATE, trying to start..."
              aws ec2 start-instances --instance-ids ${{ env.EC2_INSTANCE_ID }} || true
              aws ec2 wait instance-running --instance-ids ${{ env.EC2_INSTANCE_ID }}
              sleep 60
            fi

            # Get the public IP dynamically
            EC2_IP=$(aws ec2 describe-instances --instance-ids ${{ env.EC2_INSTANCE_ID }} --query 'Reservations[0].Instances[0].PublicIpAddress' --output text)
            echo "   EC2 Public IP: $EC2_IP"

            echo ""
            echo "üîç Step 6: Extracting DNS/WHOIS features on EC2..."
            ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -i ~/.ssh/ec2_key ec2-user@$EC2_IP << EOFEC2
              cd /home/ec2-user/phishnet

              # Update the extraction script from S3
              aws s3 cp s3://${{ env.S3_BUCKET }}/scripts/extract_vm_features_aws.py scripts/

              # Run feature extraction with batch date (this downloads, extracts, merges, and uploads to S3)
              python3.8 scripts/extract_vm_features_aws.py ${BATCH_DATE}

              echo "‚úÖ EC2 processing complete!"
          EOFEC2

            echo ""
            echo "üõë Stopping EC2 instance..."
            aws ec2 stop-instances --instance-ids ${{ env.EC2_INSTANCE_ID }}

            # ------------------------------------------------------------
            # STEP 7: Download THREE SEPARATE master files (clean feature separation)
            # ------------------------------------------------------------
            echo ""
            echo "üì• Step 7: Downloading THREE SEPARATE master datasets..."

            # Download each master file separately - ensures clean feature separation
            aws s3 cp s3://${{ env.S3_BUCKET }}/master/url_features_master.csv data/processed/url_features_master.csv 2>/dev/null || {
              echo "   Creating new URL master"
              echo "url,label" > data/processed/url_features_master.csv
            }
            aws s3 cp s3://${{ env.S3_BUCKET }}/master/dns_features_master.csv data/processed/dns_features_master.csv 2>/dev/null || {
              echo "   Creating new DNS master"
              echo "url,label" > data/processed/dns_features_master.csv
            }
            aws s3 cp s3://${{ env.S3_BUCKET }}/master/whois_features_master.csv data/processed/whois_features_master.csv 2>/dev/null || {
              echo "   Creating new WHOIS master"
              echo "url,label" > data/processed/whois_features_master.csv
            }

            URL_COUNT=$(tail -n +2 data/processed/url_features_master.csv 2>/dev/null | wc -l | tr -d ' ' || echo "0")
            DNS_COUNT=$(tail -n +2 data/processed/dns_features_master.csv 2>/dev/null | wc -l | tr -d ' ' || echo "0")
            WHOIS_COUNT=$(tail -n +2 data/processed/whois_features_master.csv 2>/dev/null | wc -l | tr -d ' ' || echo "0")
            AFTER_COUNT=$URL_COUNT

            echo "   URL master:   $URL_COUNT rows"
            echo "   DNS master:   $DNS_COUNT rows"
            echo "   WHOIS master: $WHOIS_COUNT rows"

            NEW_ADDED=$((URL_COUNT - BEFORE_COUNT))
            echo "   New URLs added: +$NEW_ADDED"

            echo ""
            echo "üèãÔ∏è Step 8: Preparing model-ready datasets from SEPARATE masters..."
            python3 << 'EOFPY'
          import pandas as pd
          import numpy as np

          # Process EACH master file SEPARATELY - no feature mixing!
          masters = {
              'url': 'data/processed/url_features_master.csv',
              'dns': 'data/processed/dns_features_master.csv',
              'whois': 'data/processed/whois_features_master.csv'
          }

          for feature_type, master_path in masters.items():
              print(f"\n--- Processing {feature_type.upper()} master ---")

              try:
                  df = pd.read_csv(master_path)
              except Exception as e:
                  print(f"  ‚ö†Ô∏è Could not load {master_path}: {e}")
                  continue

              if len(df) < 2:
                  print(f"  ‚ö†Ô∏è {feature_type.upper()} master too small ({len(df)} rows), skipping")
                  continue

              print(f"  Loaded {len(df)} rows, {len(df.columns)} columns")

              # Encode labels
              if 'label' in df.columns:
                  df['label_encoded'] = df['label'].apply(lambda x: 1 if str(x).lower() == 'phishing' else 0)
              elif 'label_encoded' not in df.columns:
                  print(f"  ‚ö†Ô∏è No label column found")
                  continue

              # Get feature columns (exclude metadata columns)
              exclude_cols = ['url', 'label', 'label_encoded', 'domain', 'collected_at', 'bucket']
              feature_cols = [c for c in df.columns if c not in exclude_cols]

              # Convert object columns to numeric
              for col in feature_cols:
                  if df[col].dtype == 'object':
                      df[col] = df[col].fillna('MISSING')
                      df[col], _ = pd.factorize(df[col])

              print(f"  Feature columns: {len(feature_cols)}")
              print(f"  Sample features: {feature_cols[:5]}...")

              # Save for training (features + label_encoded)
              df_train = df[feature_cols + ['label_encoded']].copy().fillna(0)
              df_train.to_csv(f'data/processed/{feature_type}_features_modelready_imputed.csv', index=False)

              # Save for test_ensemble_combinations (url + features + label)
              if 'url' in df.columns:
                  df_test = df[['url'] + feature_cols + ['label_encoded']].copy().fillna(0)
                  df_test = df_test.rename(columns={'label_encoded': 'label'})
                  df_test.to_csv(f'data/processed/{feature_type}_features_modelready.csv', index=False)

              print(f"  ‚úÖ Saved {feature_type}_features_modelready.csv with {len(feature_cols)} features")
          EOFPY

            echo ""
            echo "üèãÔ∏è Step 9: Training 45 models with 5-fold CV (15 per feature type)..."
            mkdir -p models analysis
            python3 << 'EOFPY'
          import pandas as pd
          import numpy as np
          from sklearn.model_selection import StratifiedKFold
          from sklearn.metrics import roc_auc_score, accuracy_score, f1_score
          from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier, BaggingClassifier
          from sklearn.linear_model import LogisticRegression
          from sklearn.tree import DecisionTreeClassifier
          from sklearn.neighbors import KNeighborsClassifier
          from sklearn.naive_bayes import GaussianNB
          from sklearn.svm import SVC
          from sklearn.neural_network import MLPClassifier
          from catboost import CatBoostClassifier
          from lightgbm import LGBMClassifier
          from xgboost import XGBClassifier
          import joblib
          import json
          import warnings
          warnings.filterwarnings('ignore')

          models = {
              'random_forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),
              'gradient_boost': GradientBoostingClassifier(n_estimators=100, random_state=42),
              'adaboost': AdaBoostClassifier(n_estimators=100, random_state=42, algorithm='SAMME'),
              'logistic': LogisticRegression(max_iter=1000, random_state=42),
              'decision_tree': DecisionTreeClassifier(random_state=42),
              'knn': KNeighborsClassifier(n_neighbors=5),
              'naive_bayes': GaussianNB(),
              'svm': SVC(probability=True, random_state=42),
              'mlp': MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42),
              'catboost': CatBoostClassifier(iterations=100, random_state=42, verbose=0),
              'lightgbm': LGBMClassifier(n_estimators=100, random_state=42, verbose=-1),
              'xgboost': XGBClassifier(n_estimators=100, random_state=42, verbosity=0),
              'extra_trees': ExtraTreesClassifier(n_estimators=100, random_state=42, n_jobs=-1),
              'bagging': BaggingClassifier(n_estimators=50, random_state=42),
              'voting_base': RandomForestClassifier(n_estimators=50, random_state=42),
          }

          skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

          # Train SEPARATE models for each feature type with 5-fold CV
          for feature_type in ['url', 'dns', 'whois']:
              print(f"\n{'='*60}")
              print(f"Training {feature_type.upper()} models with 5-fold CV...")
              print(f"{'='*60}")

              try:
                  df = pd.read_csv(f'data/processed/{feature_type}_features_modelready_imputed.csv')
              except FileNotFoundError:
                  print(f"  Skipping {feature_type} - no data file")
                  continue

              X = df.drop('label_encoded', axis=1)
              y = df['label_encoded'].values
              feature_cols = list(X.columns)

              print(f"  {len(X)} samples, {len(feature_cols)} features")

              if len(np.unique(y)) < 2:
                  print(f"  Skipping {feature_type} - only one class")
                  continue

              cv_results = []

              for name, model_template in models.items():
                  # Clone model for each iteration
                  import copy
                  fold_rocs = []
                  fold_accs = []
                  fold_f1s = []

                  try:
                      for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):
                          model = copy.deepcopy(model_template)
                          X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]
                          y_tr, y_va = y[tr_idx], y[va_idx]

                          model.fit(X_tr, y_tr)

                          if hasattr(model, 'predict_proba'):
                              probs = model.predict_proba(X_va)[:, 1]
                          else:
                              scores = model.decision_function(X_va)
                              probs = (scores - scores.min()) / (scores.max() - scores.min() + 1e-12)

                          preds = (probs >= 0.5).astype(int)

                          fold_rocs.append(roc_auc_score(y_va, probs))
                          fold_accs.append(accuracy_score(y_va, preds))
                          fold_f1s.append(f1_score(y_va, preds))

                      # Average metrics across folds
                      mean_roc = np.mean(fold_rocs)
                      mean_acc = np.mean(fold_accs)
                      mean_f1 = np.mean(fold_f1s)

                      cv_results.append({
                          'model': name,
                          'roc_auc': mean_roc,
                          'accuracy': mean_acc,
                          'f1': mean_f1
                      })

                      # Final fit on all data and save
                      final_model = copy.deepcopy(model_template)
                      final_model.fit(X, y)
                      joblib.dump(final_model, f'models/{feature_type}_{name}.pkl')
                      joblib.dump(feature_cols, f'models/{feature_type}_{name}_feature_cols.pkl')

                      print(f"    {name}: ROC={mean_roc:.4f} ACC={mean_acc:.4f} F1={mean_f1:.4f}")

                  except Exception as e:
                      print(f"    {name}: FAILED - {e}")

              # Save CV results for this feature type (needed by test_ensemble_combinations.py)
              if cv_results:
                  cv_df = pd.DataFrame(cv_results).sort_values('roc_auc', ascending=False)
                  cv_df.to_csv(f'analysis/{feature_type}_cv_results.csv', index=False)
                  print(f"\n  üìä Saved analysis/{feature_type}_cv_results.csv")
                  print(f"     Top 3: {list(cv_df.head(3)['model'].values)}")
          EOFPY

            echo ""
            echo "üîó Step 10: Testing ensemble combinations (top 3 √ó top 3 √ó top 3 √ó 4 weights = 108)..."
            python3 scripts/test_ensemble_combinations.py || {
              echo "‚ö†Ô∏è Ensemble combination testing failed, trying fallback..."
              # Fallback: use simplified ensemble comparison
              python3 scripts/ensemble_comparison.py --test-size 500 --iterations 20 || echo "Fallback also failed"
            }

            # Get best results from training
            BEST_ACC="N/A"
            BEST_F1="N/A"
            BEST_NAME="N/A"
            if [ -f "models/training_results.json" ]; then
              echo ""
              echo "üìä Training Results:"
              cat models/training_results.json
              echo ""
              BEST_ACC=$(python3 -c "
          import json
          r = json.load(open('models/training_results.json'))
          all_accs = []
          for feature_type, models in r.items():
              if models:
                  for name, acc in models.items():
                      all_accs.append(acc)
          if all_accs:
              print(f'{max(all_accs):.4f}')
          else:
              print('N/A')
          " 2>/dev/null || echo "N/A")
              echo "Best model accuracy: $BEST_ACC"
            fi

            LATEST_ENSEMBLE=$(ls -t analysis/ensemble_comparison/comparison_*.json 2>/dev/null | head -1)
            if [ -n "$LATEST_ENSEMBLE" ]; then
              echo ""
              echo "üìä Ensemble Results from: $LATEST_ENSEMBLE"
              BEST_F1=$(python3 -c "import json; r=json.load(open('$LATEST_ENSEMBLE')); print(f\"{r[0].get('f1_score', 'N/A'):.4f}\" if isinstance(r, list) and r else 'N/A')" 2>/dev/null || echo "N/A")
              BEST_NAME=$(python3 -c "import json; r=json.load(open('$LATEST_ENSEMBLE')); print(r[0].get('name', 'N/A') if isinstance(r, list) and r else 'N/A')" 2>/dev/null || echo "N/A")
              BEST_ENS_ACC=$(python3 -c "import json; r=json.load(open('$LATEST_ENSEMBLE')); print(f\"{r[0].get('accuracy', 'N/A'):.4f}\" if isinstance(r, list) and r else 'N/A')" 2>/dev/null || echo "N/A")
              echo "Best ensemble: $BEST_NAME (Accuracy: $BEST_ENS_ACC, F1: $BEST_F1)"
            else
              echo "‚ö†Ô∏è No ensemble comparison results found"
            fi

            # Record results
            echo "$RUN_NUM,$AFTER_COUNT,$NEW_ADDED,$PHISHING,$LEGIT,$BEST_ACC,$BEST_F1,$BEST_NAME" >> $RESULTS_FILE

            echo ""
            echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
            echo "‚ïë               RUN $RUN_NUM COMPLETE                              ‚ïë"
            echo "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£"
            echo "‚ïë  Dataset: $BEFORE_COUNT ‚Üí $AFTER_COUNT URLs (+$NEW_ADDED new)              "
            echo "‚ïë  Best Accuracy: $BEST_ACC                                    "
            echo "‚ïë  Best Ensemble: $BEST_NAME                                   "
            echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"

            # Small delay between runs
            sleep 5
          done

          echo ""
          echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
          echo "‚ïë            ALL VALIDATION RUNS COMPLETE                      ‚ïë"
          echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
          echo ""
          echo "Results saved to: $RESULTS_FILE"
          cat $RESULTS_FILE

      # ================================================================
      # Upload trained models to S3 for deployment workflow
      # ================================================================
      - name: Upload models to S3
        run: |
          echo ""
          echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
          echo "‚ïë           UPLOADING TRAINED MODELS TO S3                     ‚ïë"
          echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"

          # Upload all trained models (.pkl files)
          aws s3 sync models/ s3://${{ env.S3_BUCKET }}/models/ \
            --include "*.pkl" \
            --include "*.json" \
            --exclude "*_feature_cols.pkl"

          # Upload feature column files separately (needed for inference)
          aws s3 sync models/ s3://${{ env.S3_BUCKET }}/models/ \
            --include "*_feature_cols.pkl"

          echo ""
          echo "üì¶ Uploaded models:"
          aws s3 ls s3://${{ env.S3_BUCKET }}/models/ | head -30

          # Create production metadata from best ensemble
          LATEST_ENSEMBLE=$(ls -t analysis/ensemble_comparison/comparison_*.json 2>/dev/null | head -1)
          if [ -n "$LATEST_ENSEMBLE" ]; then
            echo ""
            echo "üìã Creating production_metadata.json from best ensemble..."
            python3 << EOFPY
          import json

          # Load ensemble comparison results
          with open('$LATEST_ENSEMBLE') as f:
              results = json.load(f)

          if results and isinstance(results, list):
              best = results[0]

              # Extract model names from the best ensemble
              # Format: "url_catboost + dns_lightgbm + whois_random_forest (0.4/0.3/0.3)"
              name = best.get('name', '')

              # Parse model names
              url_model = 'catboost'  # default
              dns_model = 'catboost'  # default
              whois_model = 'catboost'  # default

              if 'url_' in name:
                  parts = name.split(' + ')
                  for part in parts:
                      if part.startswith('url_'):
                          url_model = part.replace('url_', '').strip()
                      elif part.startswith('dns_'):
                          dns_model = part.replace('dns_', '').strip()
                      elif part.startswith('whois_'):
                          # Remove weight info
                          whois_part = part.split(' (')[0] if ' (' in part else part
                          whois_model = whois_part.replace('whois_', '').strip()

              metadata = {
                  'url_model': url_model,
                  'dns_model': dns_model,
                  'whois_model': whois_model,
                  'ensemble_name': name,
                  'accuracy': best.get('accuracy', 0),
                  'f1_score': best.get('f1_score', 0),
                  'roc_auc': best.get('roc_auc', 0),
                  'weights': best.get('weights', [0.4, 0.3, 0.3])
              }

              with open('models/production_metadata.json', 'w') as f:
                  json.dump(metadata, f, indent=2)

              print(f"‚úÖ Created production_metadata.json:")
              print(f"   URL model: {url_model}")
              print(f"   DNS model: {dns_model}")
              print(f"   WHOIS model: {whois_model}")
              print(f"   Accuracy: {best.get('accuracy', 0):.4f}")
              print(f"   F1 Score: {best.get('f1_score', 0):.4f}")
          else:
              print("‚ö†Ô∏è No ensemble results found, using defaults")
              metadata = {
                  'url_model': 'catboost',
                  'dns_model': 'catboost',
                  'whois_model': 'catboost'
              }
              with open('models/production_metadata.json', 'w') as f:
                  json.dump(metadata, f, indent=2)
          EOFPY

            # Upload production metadata
            aws s3 cp models/production_metadata.json s3://${{ env.S3_BUCKET }}/models/
            echo "‚úÖ Uploaded production_metadata.json to S3"
          fi

          echo ""
          echo "‚úÖ Models ready for deployment workflow!"
          echo "   Run 'Deploy Models to Production' workflow to deploy."

      - name: Upload validation results
        uses: actions/upload-artifact@v4
        with:
          name: validation-results-${{ github.run_id }}
          path: |
            analysis/validation_runs/
            analysis/ensemble_comparison/
            models/training_results.json
            models/production_metadata.json
          retention-days: 30
