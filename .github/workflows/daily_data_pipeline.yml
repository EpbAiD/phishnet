name: Daily Data Collection & Processing

on:
  schedule:
    # Run at 2 AM UTC daily (adjust timezone as needed)
    - cron: '0 2 * * *'
  workflow_dispatch:  # Allow manual trigger
    inputs:
      num_urls:
        description: 'Number of URLs to collect'
        required: false
        default: '1000'

permissions:
  contents: read
  actions: write

env:
  GCP_PROJECT_ID: coms-452404
  GCS_BUCKET: gs://phishnet-pipeline-data

jobs:
  collect-urls:
    name: Collect URLs from Sources
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Setup GCloud CLI
        uses: google-github-actions/setup-gcloud@v2

      - name: Run URL collection script
        run: |
          chmod +x scripts/collect_urls_daily.sh
          ./scripts/collect_urls_daily.sh
        env:
          NUM_URLS: ${{ github.event.inputs.num_urls || '1000' }}

      - name: Verify GCS upload
        run: |
          TIMESTAMP=$(date +%Y%m%d)
          echo "Verifying batch uploaded to Cloud Storage..."

          if gcloud storage ls ${{ env.GCS_BUCKET }}/queue/batch_${TIMESTAMP}.csv; then
            echo "✅ Batch successfully uploaded to GCS"
            echo "   Location: ${{ env.GCS_BUCKET }}/queue/batch_${TIMESTAMP}.csv"
            echo "   VM will poll and process automatically"
          else
            echo "❌ Batch file not found in GCS"
            exit 1
          fi

      - name: Get collection timestamp
        id: timestamp
        run: |
          TIMESTAMP=$(date +%Y%m%d)
          echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT
          echo "Collection timestamp: $TIMESTAMP"

      - name: Trigger VM processing monitor workflow
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            await github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'vm_processing_monitor.yml',
              ref: 'main',
              inputs: {
                timestamp: '${{ steps.timestamp.outputs.timestamp }}'
              }
            });

  notify-collection-complete:
    name: Notify Collection Status
    runs-on: ubuntu-latest
    needs: collect-urls
    if: always()

    steps:
      - name: Report success
        if: needs.collect-urls.result == 'success'
        run: |
          echo "✅ URL collection completed successfully"
          echo "URLs collected and uploaded to VM"
          echo "VM processing started in background"

      - name: Report failure
        if: needs.collect-urls.result != 'success'
        run: |
          echo "❌ URL collection failed"
          exit 1
